# -*- coding: utf-8 -*-
"""customer churn prediction using ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wcji2IpkvJSZW6Zh-U6KzH3_4Yp59EK3
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
# %matplotlib inline

df=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df.head()

"""###preprocessing"""

#Drop the unneccessary colums
df.drop("customerID",axis="columns",inplace=True)# implace= True means drop the column and UPDATE the dataset
df.dtypes

df.TotalCharges.values
#here you can see that the values are string and that is why its type is object

#convert to numeric values and also ignore the space 
pd.to_numeric(df.TotalCharges,errors="coerce").isnull()
#here isnull() is used to see whether the value is null or not

df[pd.to_numeric(df.TotalCharges,errors="coerce").isnull()]
#here you can see 11 rows have blank values for Total charges, so its drop it

df.shape

df.iloc[488] #iloc means integer location
#so here, you can see that for 488th row, Total charges is blank

df1=df[df.TotalCharges!=' ']#remove rows with empty space values for Totalcharges
df1.shape

df1.dtypes

df1.TotalCharges=pd.to_numeric(df1.TotalCharges)#after removing space convert to numeric values

df1.TotalCharges.dtypes#now totalcharges= float

#find the tenure of customers not leaving
tenure_churn_no=df1[df1.Churn=="No"].tenure
#find the tenure of customers not leaving
tenure_churn_yes=df1[df1.Churn=="Yes"].tenure
#plot in histogram
plt.xlabel("tenure")
plt.ylabel("no of customers")
plt.title("Customer_ churn prediction")
plt.hist([tenure_churn_yes,tenure_churn_no],color=['green','red'],label=['churn=Yes','churn=No'])#green--> Yes and red--> "No"
plt.legend()#to print churn=Yes and churn=No

#print columns in dataset
for column in df:
  print(column)

#to print unique values in each column
for column in df:
  print(f'{column} : {df[column].unique()}')

#print those attributes that are categorical (object/string)
def print_unique_values(df):
  for column in df:
    if df[column].dtypes=='object':
      print(f'{column} : {df[column].unique()}')

print(print_unique_values(df1))

#data cleaning
#replace "No internet service" with "No"
df1.replace('No internet service','No',inplace=True)
df1.replace('No phone service','No',inplace=True)

print(print_unique_values(df1))

#replace yes,no with 1,0
yes_no_col=['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']

for col in yes_no_col:
  df1[col].replace({'Yes':1,'No':0},inplace=True)

#print the values to see if yes is converted to 1 and no to 0
for column in df1:
      print(f'{column} : {df1[column].unique()}')

df1['gender'].replace({"Female":1,"Male":0},inplace=True)

for column in df1:
      print(f'{column} : {df1[column].unique()}')

#onehot encoding
df2=pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])
df2.columns

#randomly displaying any 4 rows
df2.sample(4)

df2.dtypes

#now we have to scale the values to same range[0,1] and for this we use minmaxscaler
col_to_scale=['tenure','MonthlyCharges','TotalCharges']

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()

df2[col_to_scale]=scaler.fit_transform(df2[col_to_scale])

df2.sample(3)

#now we can see that all values are in the range 0 to 1
for column in df2:
      print(f'{column} : {df2[column].unique()}')

"""#TRAINING"""

x=df2.drop('Churn',axis='columns')
y=df2['Churn']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5)

x_train.shape

x_test.shape

len(x_train.columns)

import tensorflow as tf
from tensorflow import keras

model=keras.Sequential([
  keras.layers.Dense(20, input_shape=(26,),activation="relu"),
  keras.layers.Dense(15, activation="relu"),
  keras.layers.Dense(1, activation="sigmoid")

])

model.compile(optimizer="adam",
              loss="binary_crossentropy",
              metrics=['accuracy']
              )

model.fit(x_train,y_train,epochs=15)

"""###testing

"""

model.evaluate(x_test,y_test)

yp=model.predict(x_test)
yp[:5]#the oupt is a 2D array

y_test[:5]

#convert 2D to 1D array(if value is less than 0.5-->0 else make it 1)
y_pred=[]
for element in yp:
  if element > 0.5:
    y_pred.append(1)
  else:
    y_pred.append(0)

y_pred[:5]

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test,y_pred))

#here, the diagonal values are the correctly predicted 
import seaborn as sn
cm=tf.math.confusion_matrix(labels=y_test, predictions=y_pred)

plt.figure(figsize=(10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel("predicted")
plt.ylabel("truth")

#accuracy=total correctly predicted/total predictions
#round((904+203)/(904+203+95+205),2)

#precision= correctly predicted as 0/ total predicted as 0
#round(904/(904+205),2)#precision for class 0

#precision= correctly predicted as 1/ total predicted as 1
#round(203/(95+203),2)#precision for class 1

#recall for class 0=correctly predicted for 0/ actual for 0
#round(904/(904+95),2)

#recall for class 0=correctly predicted for 1/ actual for 1
#round(203/(203+205),2)